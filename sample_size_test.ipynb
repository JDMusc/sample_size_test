{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "MyRSykLd2khw"
   },
   "outputs": [],
   "source": [
    "# Some imports, we are not gong to use all the imports in this workbook but in subsequent workbooks we surely will.\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from toolz import pipe as p\n",
    "import tensorflow as tf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'models' from 'C:\\\\Users\\\\jod204\\\\projects\\\\jo\\\\samplesize_test\\\\models.py'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import model_runs\n",
    "import models as models\n",
    "import utils as u\n",
    "\n",
    "from importlib import reload\n",
    "reload(u)\n",
    "reload(model_runs)\n",
    "reload(models)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MCsYaAYFXD9d"
   },
   "source": [
    "# Settings and Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "BUO08cgp2lDj"
   },
   "outputs": [],
   "source": [
    "# Define some Global Variables\n",
    "max_features = 20000 # Maximum Number of words we want to include in our dictionary\n",
    "maxlen = 400 # No of words in question we want to create a sequence with\n",
    "embed_size = 50# Size of word to vec embedding we are using\n",
    "\n",
    "\n",
    "def get_log_dir(iteration, samples_per_class):\n",
    "    return f\"output/{samples_per_class}/{iteration}/\"\n",
    "\n",
    "\n",
    "def save_series_gen(log_dir, prefix):\n",
    "    def save_series(series, name):\n",
    "        series.to_csv(f'{log_dir}/{prefix}_{name}.csv', index = False, header = False)\n",
    "    \n",
    "    return save_series\n",
    "\n",
    "\n",
    "def log_truths(log_dir, train_y, val_y, test_y):\n",
    "    save_series = save_series_gen(log_dir, 'true')\n",
    "        \n",
    "    save_series(train_y, 'train')\n",
    "    save_series(val_y, 'val')\n",
    "    save_series(test_y, 'test')\n",
    "\n",
    "\n",
    "def log_iteration_preds(log_dir, model_name,\n",
    "                  pred_train_y, pred_val_y, pred_test_y,\n",
    "                  one_train_time):\n",
    "    def save_arr(arr, name):\n",
    "        arr.tofile(f'{log_dir}/{model_name}_{name}.csv', sep = ',')\n",
    "    \n",
    "    save_arr(pred_train_y, 'pred_train')\n",
    "    save_arr(pred_val_y, 'pred_val')\n",
    "    save_arr(pred_test_y, 'pred_test')\n",
    "    p(one_train_time,\n",
    "      np.array,\n",
    "      lambda _: save_arr(_, 'time'))\n",
    "\n",
    "\n",
    "def run_and_log_model(model, model_name, train_X, train_y, val_X, val_y, test_X, iteration, samples_per_class):\n",
    "    start_time = time.perf_counter()\n",
    "    pred_train_y, pred_val_y, pred_test_y = model_runs.train_pred(model, train_X, train_y,\n",
    "                                          val_X, val_y, test_X, epochs=50)\n",
    "    end_time = time.perf_counter()\n",
    "    one_train_time = end_time - start_time\n",
    "    \n",
    "    dir_name = get_log_dir(iteration, samples_per_class)\n",
    "    log_iteration_preds(dir_name, model_name, \n",
    "                  pred_train_y, pred_val_y, pred_test_y,\n",
    "                  one_train_time) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fj_RUg6dRBeK"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "500\n",
      "500\n",
      "X shape :  (1000,)\n",
      "y shape :  (1000,)\n",
      "400\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 400, 50)      1000000     input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_3 (Reshape)             (None, 400, 50, 1)   0           embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 398, 1, 200)  30200       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 397, 1, 200)  40200       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 396, 1, 200)  50200       reshape_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 3, 1, 200)    0           max_pooling2d_4[0][0]            \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_2 (Flatten)             (None, 600)          0           concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 600)          0           flatten_2[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 600)          0           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            601         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,121,201\n",
      "Trainable params: 1,121,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "603/603 [==============================] - 1s 1ms/step - loss: 0.7508 - acc: 0.4975 - val_loss: 0.7290 - val_acc: 0.5522\n",
      "Epoch 2/50\n",
      "603/603 [==============================] - 0s 196us/step - loss: 0.7271 - acc: 0.5091 - val_loss: 0.7118 - val_acc: 0.5522\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - 0s 188us/step - loss: 0.7114 - acc: 0.5041 - val_loss: 0.7009 - val_acc: 0.5522\n",
      "Epoch 4/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.7013 - acc: 0.5041 - val_loss: 0.6935 - val_acc: 0.5522\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.6939 - acc: 0.5041 - val_loss: 0.6876 - val_acc: 0.5522\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - 0s 177us/step - loss: 0.6877 - acc: 0.5075 - val_loss: 0.6815 - val_acc: 0.5522\n",
      "Epoch 7/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.6810 - acc: 0.5821 - val_loss: 0.6739 - val_acc: 0.7910\n",
      "Epoch 8/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.6730 - acc: 0.8590 - val_loss: 0.6645 - val_acc: 0.8955\n",
      "Epoch 9/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.6624 - acc: 0.9386 - val_loss: 0.6526 - val_acc: 0.9254\n",
      "Epoch 10/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.6490 - acc: 0.9502 - val_loss: 0.6382 - val_acc: 0.9104\n",
      "Epoch 11/50\n",
      "603/603 [==============================] - 0s 170us/step - loss: 0.6334 - acc: 0.9552 - val_loss: 0.6219 - val_acc: 0.9104\n",
      "Epoch 12/50\n",
      "603/603 [==============================] - 0s 188us/step - loss: 0.6160 - acc: 0.9602 - val_loss: 0.6045 - val_acc: 0.9254\n",
      "Epoch 13/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.5949 - acc: 0.9585 - val_loss: 0.5865 - val_acc: 0.9254\n",
      "Epoch 14/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.5727 - acc: 0.9685 - val_loss: 0.5681 - val_acc: 0.9254\n",
      "Epoch 15/50\n",
      "603/603 [==============================] - 0s 177us/step - loss: 0.5500 - acc: 0.9652 - val_loss: 0.5495 - val_acc: 0.9254\n",
      "Epoch 16/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.5267 - acc: 0.9668 - val_loss: 0.5310 - val_acc: 0.9104\n",
      "Epoch 17/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.5016 - acc: 0.9701 - val_loss: 0.5125 - val_acc: 0.9104\n",
      "Epoch 18/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.4777 - acc: 0.9701 - val_loss: 0.4948 - val_acc: 0.9254\n",
      "Epoch 19/50\n",
      "603/603 [==============================] - 0s 194us/step - loss: 0.4529 - acc: 0.9718 - val_loss: 0.4780 - val_acc: 0.9254\n",
      "Epoch 20/50\n",
      "603/603 [==============================] - 0s 168us/step - loss: 0.4291 - acc: 0.9701 - val_loss: 0.4630 - val_acc: 0.9254\n",
      "Epoch 21/50\n",
      "603/603 [==============================] - 0s 162us/step - loss: 0.4067 - acc: 0.9652 - val_loss: 0.4503 - val_acc: 0.9254\n",
      "Epoch 22/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.3864 - acc: 0.9569 - val_loss: 0.4386 - val_acc: 0.9254\n",
      "Epoch 23/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.3683 - acc: 0.9585 - val_loss: 0.4259 - val_acc: 0.9254\n",
      "Epoch 24/50\n",
      "603/603 [==============================] - 0s 177us/step - loss: 0.3516 - acc: 0.9585 - val_loss: 0.4126 - val_acc: 0.9254\n",
      "Epoch 25/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.3341 - acc: 0.9585 - val_loss: 0.3993 - val_acc: 0.9254\n",
      "Epoch 26/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.3181 - acc: 0.9668 - val_loss: 0.3868 - val_acc: 0.9254\n",
      "Epoch 27/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.3030 - acc: 0.9718 - val_loss: 0.3760 - val_acc: 0.9254\n",
      "Epoch 28/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.2883 - acc: 0.9768 - val_loss: 0.3665 - val_acc: 0.9254\n",
      "Epoch 29/50\n",
      "603/603 [==============================] - 0s 170us/step - loss: 0.2748 - acc: 0.9768 - val_loss: 0.3585 - val_acc: 0.9254\n",
      "Epoch 30/50\n",
      "603/603 [==============================] - 0s 188us/step - loss: 0.2627 - acc: 0.9751 - val_loss: 0.3515 - val_acc: 0.9254\n",
      "Epoch 31/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.2518 - acc: 0.9801 - val_loss: 0.3455 - val_acc: 0.9254\n",
      "Epoch 32/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.2423 - acc: 0.9751 - val_loss: 0.3397 - val_acc: 0.9254\n",
      "Epoch 33/50\n",
      "603/603 [==============================] - 0s 177us/step - loss: 0.2315 - acc: 0.9818 - val_loss: 0.3344 - val_acc: 0.9254\n",
      "Epoch 34/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.2236 - acc: 0.9834 - val_loss: 0.3287 - val_acc: 0.9254\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "603/603 [==============================] - 0s 166us/step - loss: 0.2160 - acc: 0.9818 - val_loss: 0.3218 - val_acc: 0.9254\n",
      "Epoch 36/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.2084 - acc: 0.9834 - val_loss: 0.3153 - val_acc: 0.9254\n",
      "Epoch 37/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.2033 - acc: 0.9834 - val_loss: 0.3118 - val_acc: 0.9254\n",
      "Epoch 38/50\n",
      "603/603 [==============================] - 0s 171us/step - loss: 0.1956 - acc: 0.9834 - val_loss: 0.3102 - val_acc: 0.9254\n",
      "Epoch 39/50\n",
      "603/603 [==============================] - 0s 188us/step - loss: 0.1898 - acc: 0.9834 - val_loss: 0.3065 - val_acc: 0.9254\n",
      "Epoch 40/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.1844 - acc: 0.9818 - val_loss: 0.3005 - val_acc: 0.9254\n",
      "Epoch 41/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.1799 - acc: 0.9834 - val_loss: 0.2959 - val_acc: 0.9254\n",
      "Epoch 42/50\n",
      "603/603 [==============================] - 0s 177us/step - loss: 0.1729 - acc: 0.9834 - val_loss: 0.2951 - val_acc: 0.9254\n",
      "Epoch 43/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.1676 - acc: 0.9834 - val_loss: 0.2959 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 44/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.1657 - acc: 0.9834 - val_loss: 0.2956 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00044: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 45/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.1633 - acc: 0.9834 - val_loss: 0.2953 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 46/50\n",
      "603/603 [==============================] - 0s 177us/step - loss: 0.1617 - acc: 0.9851 - val_loss: 0.2949 - val_acc: 0.9254\n",
      "Epoch 47/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.1611 - acc: 0.9851 - val_loss: 0.2942 - val_acc: 0.9254\n",
      "Epoch 48/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.1607 - acc: 0.9851 - val_loss: 0.2933 - val_acc: 0.9254\n",
      "Epoch 49/50\n",
      "603/603 [==============================] - 0s 192us/step - loss: 0.1605 - acc: 0.9851 - val_loss: 0.2920 - val_acc: 0.9254\n",
      "Epoch 50/50\n",
      "603/603 [==============================] - 0s 166us/step - loss: 0.1589 - acc: 0.9851 - val_loss: 0.2905 - val_acc: 0.9254\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 400, 50)      1000000     input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 400, 128)     58880       embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_1 (Glo (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_1 (GlobalM (None, 128)          0           bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256)          0           global_average_pooling1d_1[0][0] \n",
      "                                                                 global_max_pooling1d_1[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 64)           16448       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_3 (Dropout)             (None, 64)           0           dense_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 1)            65          dropout_3[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,075,393\n",
      "Trainable params: 1,075,393\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "603/603 [==============================] - 4s 6ms/step - loss: 0.6931 - acc: 0.5224 - val_loss: 0.6930 - val_acc: 0.4776\n",
      "Epoch 2/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6920 - acc: 0.6119 - val_loss: 0.6924 - val_acc: 0.5821\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6906 - acc: 0.6750 - val_loss: 0.6902 - val_acc: 0.5522\n",
      "Epoch 4/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6892 - acc: 0.5158 - val_loss: 0.6884 - val_acc: 0.5522\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6871 - acc: 0.5108 - val_loss: 0.6874 - val_acc: 0.5522\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6844 - acc: 0.5688 - val_loss: 0.6860 - val_acc: 0.6567\n",
      "Epoch 7/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6807 - acc: 0.7197 - val_loss: 0.6837 - val_acc: 0.7313\n",
      "Epoch 8/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6762 - acc: 0.8624 - val_loss: 0.6808 - val_acc: 0.8209\n",
      "Epoch 9/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6694 - acc: 0.9552 - val_loss: 0.6760 - val_acc: 0.7910\n",
      "Epoch 10/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6604 - acc: 0.9486 - val_loss: 0.6669 - val_acc: 0.8209\n",
      "Epoch 11/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6458 - acc: 0.9735 - val_loss: 0.6503 - val_acc: 0.8657\n",
      "Epoch 12/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.6230 - acc: 0.9751 - val_loss: 0.6254 - val_acc: 0.8806\n",
      "Epoch 13/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.5826 - acc: 0.9768 - val_loss: 0.5864 - val_acc: 0.8060\n",
      "Epoch 14/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.4956 - acc: 0.9585 - val_loss: 0.4596 - val_acc: 0.8209\n",
      "Epoch 15/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.3179 - acc: 0.9154 - val_loss: 0.5305 - val_acc: 0.7910\n",
      "\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 16/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.2043 - acc: 0.9453 - val_loss: 0.5884 - val_acc: 0.7761\n",
      "\n",
      "Epoch 00016: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 17/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.1960 - acc: 0.9469 - val_loss: 0.5954 - val_acc: 0.7761\n",
      "\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 18/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.1851 - acc: 0.9486 - val_loss: 0.5818 - val_acc: 0.7761\n",
      "\n",
      "Epoch 00018: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 19/50\n",
      "603/603 [==============================] - 2s 3ms/step - loss: 0.1711 - acc: 0.9519 - val_loss: 0.5678 - val_acc: 0.7761\n",
      "Epoch 00019: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_4 (Embedding)      (None, 400, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_2 (Bidirection (None, 400, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_3 (Bidirection (None, 400, 128)          164352    \n",
      "_________________________________________________________________\n",
      "attention_with_context_1 (At (None, 128)               16640     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,372,609\n",
      "Trainable params: 1,372,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 603 samples, validate on 67 samples\n",
      "Epoch 1/50\n",
      "603/603 [==============================] - 7s 12ms/step - loss: 0.6939 - acc: 0.4693 - val_loss: 0.6928 - val_acc: 0.5522\n",
      "Epoch 2/50\n",
      "603/603 [==============================] - 4s 7ms/step - loss: 0.6930 - acc: 0.5158 - val_loss: 0.6942 - val_acc: 0.4478\n",
      "\n",
      "Epoch 00002: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 3/50\n",
      "603/603 [==============================] - 4s 7ms/step - loss: 0.6931 - acc: 0.4959 - val_loss: 0.6943 - val_acc: 0.4478\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 4/50\n",
      "603/603 [==============================] - 4s 7ms/step - loss: 0.6930 - acc: 0.4959 - val_loss: 0.6940 - val_acc: 0.4478\n",
      "\n",
      "Epoch 00004: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 5/50\n",
      "603/603 [==============================] - 4s 7ms/step - loss: 0.6929 - acc: 0.4959 - val_loss: 0.6938 - val_acc: 0.4478\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 6/50\n",
      "603/603 [==============================] - 4s 7ms/step - loss: 0.6928 - acc: 0.4959 - val_loss: 0.6936 - val_acc: 0.4478\n",
      "Epoch 00006: early stopping\n",
      "2000\n",
      "1000\n",
      "1000\n",
      "X shape :  (2000,)\n",
      "y shape :  (2000,)\n",
      "400\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, 400, 50)      1000000     input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_5 (Reshape)             (None, 400, 50, 1)   0           embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 398, 1, 200)  30200       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 397, 1, 200)  40200       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 396, 1, 200)  50200       reshape_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 1, 1, 200)    0           conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 1, 200)    0           max_pooling2d_7[0][0]            \n",
      "                                                                 max_pooling2d_8[0][0]            \n",
      "                                                                 max_pooling2d_9[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 600)          0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_6 (Reshape)             (None, 600)          0           flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_4 (Dropout)             (None, 600)          0           reshape_6[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 1)            601         dropout_4[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,121,201\n",
      "Trainable params: 1,121,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1206 samples, validate on 134 samples\n",
      "Epoch 1/50\n",
      "1206/1206 [==============================] - 2s 1ms/step - loss: 0.7440 - acc: 0.4884 - val_loss: 0.7198 - val_acc: 0.5149\n",
      "Epoch 2/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.7145 - acc: 0.5025 - val_loss: 0.7016 - val_acc: 0.5224\n",
      "Epoch 3/50\n",
      "1206/1206 [==============================] - 0s 181us/step - loss: 0.6982 - acc: 0.6973 - val_loss: 0.6916 - val_acc: 0.4851\n",
      "Epoch 4/50\n",
      "1206/1206 [==============================] - 0s 183us/step - loss: 0.6885 - acc: 0.4992 - val_loss: 0.6828 - val_acc: 0.4851\n",
      "Epoch 5/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.6778 - acc: 0.4975 - val_loss: 0.6710 - val_acc: 0.4851\n",
      "Epoch 6/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.6636 - acc: 0.5647 - val_loss: 0.6545 - val_acc: 0.7313\n",
      "Epoch 7/50\n",
      "1206/1206 [==============================] - 0s 192us/step - loss: 0.6420 - acc: 0.8839 - val_loss: 0.6320 - val_acc: 0.8657\n",
      "Epoch 8/50\n",
      "1206/1206 [==============================] - 0s 181us/step - loss: 0.6133 - acc: 0.9486 - val_loss: 0.6059 - val_acc: 0.8881\n",
      "Epoch 9/50\n",
      "1206/1206 [==============================] - 0s 182us/step - loss: 0.5807 - acc: 0.9519 - val_loss: 0.5781 - val_acc: 0.8881\n",
      "Epoch 10/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.5442 - acc: 0.9577 - val_loss: 0.5500 - val_acc: 0.9179\n",
      "Epoch 11/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.5063 - acc: 0.9561 - val_loss: 0.5217 - val_acc: 0.9179\n",
      "Epoch 12/50\n",
      "1206/1206 [==============================] - 0s 181us/step - loss: 0.4692 - acc: 0.9527 - val_loss: 0.4960 - val_acc: 0.9179\n",
      "Epoch 13/50\n",
      "1206/1206 [==============================] - 0s 177us/step - loss: 0.4338 - acc: 0.9502 - val_loss: 0.4733 - val_acc: 0.9179\n",
      "Epoch 14/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.4012 - acc: 0.9494 - val_loss: 0.4533 - val_acc: 0.9179\n",
      "Epoch 15/50\n",
      "1206/1206 [==============================] - 0s 172us/step - loss: 0.3724 - acc: 0.9502 - val_loss: 0.4353 - val_acc: 0.9179\n",
      "Epoch 16/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.3463 - acc: 0.9552 - val_loss: 0.4189 - val_acc: 0.9179\n",
      "Epoch 17/50\n",
      "1206/1206 [==============================] - 0s 192us/step - loss: 0.3212 - acc: 0.9635 - val_loss: 0.4031 - val_acc: 0.9179\n",
      "Epoch 18/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.3005 - acc: 0.9643 - val_loss: 0.3885 - val_acc: 0.9179\n",
      "Epoch 19/50\n",
      "1206/1206 [==============================] - 0s 183us/step - loss: 0.2794 - acc: 0.9652 - val_loss: 0.3766 - val_acc: 0.9179\n",
      "Epoch 20/50\n",
      "1206/1206 [==============================] - 0s 180us/step - loss: 0.2627 - acc: 0.9652 - val_loss: 0.3672 - val_acc: 0.9179\n",
      "Epoch 21/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.2480 - acc: 0.9710 - val_loss: 0.3595 - val_acc: 0.9179\n",
      "Epoch 22/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.2344 - acc: 0.9735 - val_loss: 0.3526 - val_acc: 0.9179\n",
      "Epoch 23/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.2222 - acc: 0.9743 - val_loss: 0.3469 - val_acc: 0.9179\n",
      "Epoch 24/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.2115 - acc: 0.9768 - val_loss: 0.3418 - val_acc: 0.9179\n",
      "Epoch 25/50\n",
      "1206/1206 [==============================] - 0s 184us/step - loss: 0.2017 - acc: 0.9768 - val_loss: 0.3376 - val_acc: 0.9179\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1919 - acc: 0.9784 - val_loss: 0.3342 - val_acc: 0.9179\n",
      "Epoch 27/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1843 - acc: 0.9793 - val_loss: 0.3305 - val_acc: 0.9179\n",
      "Epoch 28/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1773 - acc: 0.9818 - val_loss: 0.3273 - val_acc: 0.9179\n",
      "Epoch 29/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1714 - acc: 0.9842 - val_loss: 0.3256 - val_acc: 0.9104\n",
      "Epoch 30/50\n",
      "1206/1206 [==============================] - 0s 184us/step - loss: 0.1639 - acc: 0.9859 - val_loss: 0.3238 - val_acc: 0.9179\n",
      "Epoch 31/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1590 - acc: 0.9842 - val_loss: 0.3213 - val_acc: 0.9179\n",
      "Epoch 32/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1546 - acc: 0.9859 - val_loss: 0.3181 - val_acc: 0.9179\n",
      "Epoch 33/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1493 - acc: 0.9859 - val_loss: 0.3167 - val_acc: 0.9179\n",
      "Epoch 34/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1426 - acc: 0.9859 - val_loss: 0.3163 - val_acc: 0.9179\n",
      "Epoch 35/50\n",
      "1206/1206 [==============================] - 0s 185us/step - loss: 0.1381 - acc: 0.9867 - val_loss: 0.3154 - val_acc: 0.9179\n",
      "Epoch 36/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1352 - acc: 0.9876 - val_loss: 0.3147 - val_acc: 0.9179\n",
      "Epoch 37/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1300 - acc: 0.9876 - val_loss: 0.3125 - val_acc: 0.9179\n",
      "Epoch 38/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1278 - acc: 0.9876 - val_loss: 0.3115 - val_acc: 0.9179\n",
      "Epoch 39/50\n",
      "1206/1206 [==============================] - 0s 180us/step - loss: 0.1241 - acc: 0.9884 - val_loss: 0.3106 - val_acc: 0.9179\n",
      "Epoch 40/50\n",
      "1206/1206 [==============================] - 0s 191us/step - loss: 0.1209 - acc: 0.9876 - val_loss: 0.3107 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 41/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1175 - acc: 0.9876 - val_loss: 0.3113 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 42/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1170 - acc: 0.9892 - val_loss: 0.3108 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00042: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 43/50\n",
      "1206/1206 [==============================] - 0s 186us/step - loss: 0.1159 - acc: 0.9884 - val_loss: 0.3100 - val_acc: 0.9179\n",
      "Epoch 44/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1163 - acc: 0.9876 - val_loss: 0.3094 - val_acc: 0.9179\n",
      "Epoch 45/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1155 - acc: 0.9884 - val_loss: 0.3091 - val_acc: 0.9179\n",
      "Epoch 46/50\n",
      "1206/1206 [==============================] - 0s 179us/step - loss: 0.1151 - acc: 0.9876 - val_loss: 0.3088 - val_acc: 0.9179\n",
      "Epoch 47/50\n",
      "1206/1206 [==============================] - 0s 181us/step - loss: 0.1147 - acc: 0.9892 - val_loss: 0.3086 - val_acc: 0.9179\n",
      "Epoch 48/50\n",
      "1206/1206 [==============================] - 0s 182us/step - loss: 0.1140 - acc: 0.9884 - val_loss: 0.3084 - val_acc: 0.9179\n",
      "Epoch 49/50\n",
      "1206/1206 [==============================] - 0s 180us/step - loss: 0.1135 - acc: 0.9884 - val_loss: 0.3083 - val_acc: 0.9179\n",
      "Epoch 50/50\n",
      "1206/1206 [==============================] - 0s 190us/step - loss: 0.1141 - acc: 0.9876 - val_loss: 0.3085 - val_acc: 0.9179\n",
      "\n",
      "Epoch 00050: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_6 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_6 (Embedding)         (None, 400, 50)      1000000     input_6[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 400, 128)     58880       embedding_6[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_2 (Glo (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_2 (GlobalM (None, 128)          0           bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_5 (Concatenate)     (None, 256)          0           global_average_pooling1d_2[0][0] \n",
      "                                                                 global_max_pooling1d_2[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           16448       concatenate_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 64)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            65          dropout_5[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,075,393\n",
      "Trainable params: 1,075,393\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1206 samples, validate on 134 samples\n",
      "Epoch 1/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.6931 - acc: 0.4959 - val_loss: 0.6924 - val_acc: 0.5149\n",
      "Epoch 2/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.6918 - acc: 0.5174 - val_loss: 0.6915 - val_acc: 0.5149\n",
      "Epoch 3/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.6900 - acc: 0.5282 - val_loss: 0.6903 - val_acc: 0.5149\n",
      "Epoch 4/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.6877 - acc: 0.5771 - val_loss: 0.6883 - val_acc: 0.6493\n",
      "Epoch 5/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.6834 - acc: 0.7595 - val_loss: 0.6843 - val_acc: 0.7090\n",
      "Epoch 6/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.6766 - acc: 0.8342 - val_loss: 0.6770 - val_acc: 0.7612\n",
      "Epoch 7/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.6635 - acc: 0.8731 - val_loss: 0.6624 - val_acc: 0.7836\n",
      "Epoch 8/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.6374 - acc: 0.8922 - val_loss: 0.6311 - val_acc: 0.7836\n",
      "Epoch 9/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.5780 - acc: 0.9386 - val_loss: 0.5568 - val_acc: 0.7313\n",
      "Epoch 10/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.4176 - acc: 0.9038 - val_loss: 0.5152 - val_acc: 0.7612\n",
      "Epoch 11/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.2564 - acc: 0.9096 - val_loss: 0.6918 - val_acc: 0.7313\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 12/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.2486 - acc: 0.8831 - val_loss: 0.6741 - val_acc: 0.7612\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 13/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.2262 - acc: 0.8964 - val_loss: 0.6567 - val_acc: 0.7687\n",
      "\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.2086 - acc: 0.9030 - val_loss: 0.6548 - val_acc: 0.7687\n",
      "\n",
      "Epoch 00014: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 15/50\n",
      "1206/1206 [==============================] - 3s 2ms/step - loss: 0.1833 - acc: 0.9129 - val_loss: 0.6694 - val_acc: 0.7537\n",
      "Epoch 00015: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_7 (InputLayer)         (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_7 (Embedding)      (None, 400, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_5 (Bidirection (None, 400, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_6 (Bidirection (None, 400, 128)          164352    \n",
      "_________________________________________________________________\n",
      "attention_with_context_2 (At (None, 128)               16640     \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,372,609\n",
      "Trainable params: 1,372,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1206 samples, validate on 134 samples\n",
      "Epoch 1/50\n",
      "1206/1206 [==============================] - 9s 8ms/step - loss: 0.6931 - acc: 0.5041 - val_loss: 0.6925 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.6929 - acc: 0.4942 - val_loss: 0.6923 - val_acc: 0.5821\n",
      "Epoch 3/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.6917 - acc: 0.5299 - val_loss: 0.6898 - val_acc: 0.5597\n",
      "Epoch 4/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.6876 - acc: 0.6144 - val_loss: 0.6783 - val_acc: 0.6418\n",
      "Epoch 5/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.6704 - acc: 0.6998 - val_loss: 0.6425 - val_acc: 0.7463\n",
      "Epoch 6/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.6019 - acc: 0.8582 - val_loss: 0.5186 - val_acc: 0.7612\n",
      "Epoch 7/50\n",
      "1206/1206 [==============================] - 5s 5ms/step - loss: 0.4372 - acc: 0.8201 - val_loss: 0.6108 - val_acc: 0.6791\n",
      "\n",
      "Epoch 00007: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 8/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.3248 - acc: 0.8673 - val_loss: 0.4412 - val_acc: 0.8060\n",
      "Epoch 9/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.2393 - acc: 0.9163 - val_loss: 0.4657 - val_acc: 0.8134\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 10/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.1990 - acc: 0.9345 - val_loss: 0.4395 - val_acc: 0.8060\n",
      "Epoch 11/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.1651 - acc: 0.9420 - val_loss: 0.4807 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.1600 - acc: 0.9370 - val_loss: 0.4908 - val_acc: 0.7985\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 13/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.1441 - acc: 0.9461 - val_loss: 0.4865 - val_acc: 0.7985\n",
      "Epoch 14/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.1260 - acc: 0.9552 - val_loss: 0.4876 - val_acc: 0.8060\n",
      "Epoch 15/50\n",
      "1206/1206 [==============================] - 5s 4ms/step - loss: 0.1136 - acc: 0.9610 - val_loss: 0.4988 - val_acc: 0.8134\n",
      "Epoch 00015: early stopping\n",
      "3000\n",
      "1500\n",
      "1500\n",
      "X shape :  (3000,)\n",
      "y shape :  (3000,)\n",
      "400\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_8 (Embedding)         (None, 400, 50)      1000000     input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "reshape_7 (Reshape)             (None, 400, 50, 1)   0           embedding_8[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 398, 1, 200)  30200       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 397, 1, 200)  40200       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 396, 1, 200)  50200       reshape_7[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 1, 1, 200)    0           conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 1, 1, 200)    0           conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 1, 1, 200)    0           conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 3, 1, 200)    0           max_pooling2d_10[0][0]           \n",
      "                                                                 max_pooling2d_11[0][0]           \n",
      "                                                                 max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 600)          0           concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "reshape_8 (Reshape)             (None, 600)          0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 600)          0           reshape_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 1)            601         dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,121,201\n",
      "Trainable params: 1,121,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Train on 1809 samples, validate on 201 samples\n",
      "Epoch 1/50\n",
      "1809/1809 [==============================] - 3s 1ms/step - loss: 0.7379 - acc: 0.4947 - val_loss: 0.7124 - val_acc: 0.4826\n",
      "Epoch 2/50\n",
      "1809/1809 [==============================] - 0s 180us/step - loss: 0.7045 - acc: 0.5384 - val_loss: 0.6932 - val_acc: 0.4826\n",
      "Epoch 3/50\n",
      "1809/1809 [==============================] - 0s 180us/step - loss: 0.6862 - acc: 0.5053 - val_loss: 0.6778 - val_acc: 0.4826\n",
      "Epoch 4/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.6672 - acc: 0.5119 - val_loss: 0.6566 - val_acc: 0.6965\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.6390 - acc: 0.8612 - val_loss: 0.6268 - val_acc: 0.9055\n",
      "Epoch 6/50\n",
      "1809/1809 [==============================] - 0s 178us/step - loss: 0.6009 - acc: 0.9453 - val_loss: 0.5921 - val_acc: 0.9104\n",
      "Epoch 7/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.5564 - acc: 0.9547 - val_loss: 0.5576 - val_acc: 0.9055\n",
      "Epoch 8/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.5105 - acc: 0.9569 - val_loss: 0.5225 - val_acc: 0.9055\n",
      "Epoch 9/50\n",
      "1809/1809 [==============================] - 0s 185us/step - loss: 0.4632 - acc: 0.9508 - val_loss: 0.4904 - val_acc: 0.9104\n",
      "Epoch 10/50\n",
      "1809/1809 [==============================] - 0s 177us/step - loss: 0.4205 - acc: 0.9469 - val_loss: 0.4616 - val_acc: 0.9104\n",
      "Epoch 11/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.3827 - acc: 0.9464 - val_loss: 0.4364 - val_acc: 0.9104\n",
      "Epoch 12/50\n",
      "1809/1809 [==============================] - 0s 185us/step - loss: 0.3492 - acc: 0.9480 - val_loss: 0.4140 - val_acc: 0.9154\n",
      "Epoch 13/50\n",
      "1809/1809 [==============================] - 0s 177us/step - loss: 0.3192 - acc: 0.9563 - val_loss: 0.3928 - val_acc: 0.9204\n",
      "Epoch 14/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.2924 - acc: 0.9574 - val_loss: 0.3743 - val_acc: 0.9254\n",
      "Epoch 15/50\n",
      "1809/1809 [==============================] - 0s 185us/step - loss: 0.2709 - acc: 0.9646 - val_loss: 0.3612 - val_acc: 0.9254\n",
      "Epoch 16/50\n",
      "1809/1809 [==============================] - 0s 186us/step - loss: 0.2517 - acc: 0.9707 - val_loss: 0.3471 - val_acc: 0.9254\n",
      "Epoch 17/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.2354 - acc: 0.9690 - val_loss: 0.3356 - val_acc: 0.9303\n",
      "Epoch 18/50\n",
      "1809/1809 [==============================] - 0s 176us/step - loss: 0.2209 - acc: 0.9718 - val_loss: 0.3282 - val_acc: 0.9303\n",
      "Epoch 19/50\n",
      "1809/1809 [==============================] - 0s 182us/step - loss: 0.2078 - acc: 0.9762 - val_loss: 0.3195 - val_acc: 0.9303\n",
      "Epoch 20/50\n",
      "1809/1809 [==============================] - 0s 187us/step - loss: 0.1967 - acc: 0.9784 - val_loss: 0.3131 - val_acc: 0.9303\n",
      "Epoch 21/50\n",
      "1809/1809 [==============================] - 0s 176us/step - loss: 0.1865 - acc: 0.9779 - val_loss: 0.3068 - val_acc: 0.9303\n",
      "Epoch 22/50\n",
      "1809/1809 [==============================] - 0s 174us/step - loss: 0.1795 - acc: 0.9779 - val_loss: 0.3022 - val_acc: 0.9254\n",
      "Epoch 23/50\n",
      "1809/1809 [==============================] - 0s 179us/step - loss: 0.1711 - acc: 0.9823 - val_loss: 0.2978 - val_acc: 0.9254\n",
      "Epoch 24/50\n",
      "1809/1809 [==============================] - 0s 186us/step - loss: 0.1631 - acc: 0.9818 - val_loss: 0.2914 - val_acc: 0.9303\n",
      "Epoch 25/50\n",
      "1809/1809 [==============================] - 0s 181us/step - loss: 0.1572 - acc: 0.9812 - val_loss: 0.2908 - val_acc: 0.9254\n",
      "Epoch 26/50\n",
      "1809/1809 [==============================] - 0s 187us/step - loss: 0.1520 - acc: 0.9845 - val_loss: 0.2872 - val_acc: 0.9254\n",
      "Epoch 27/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.1455 - acc: 0.9845 - val_loss: 0.2831 - val_acc: 0.9303\n",
      "Epoch 28/50\n",
      "1809/1809 [==============================] - 0s 183us/step - loss: 0.1411 - acc: 0.9845 - val_loss: 0.2837 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 29/50\n",
      "1809/1809 [==============================] - 0s 176us/step - loss: 0.1371 - acc: 0.9845 - val_loss: 0.2797 - val_acc: 0.9254\n",
      "Epoch 30/50\n",
      "1809/1809 [==============================] - 0s 179us/step - loss: 0.1354 - acc: 0.9840 - val_loss: 0.2786 - val_acc: 0.9254\n",
      "Epoch 31/50\n",
      "1809/1809 [==============================] - 0s 187us/step - loss: 0.1325 - acc: 0.9856 - val_loss: 0.2809 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 32/50\n",
      "1809/1809 [==============================] - 0s 178us/step - loss: 0.1299 - acc: 0.9862 - val_loss: 0.2787 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 33/50\n",
      "1809/1809 [==============================] - 0s 187us/step - loss: 0.1294 - acc: 0.9851 - val_loss: 0.2773 - val_acc: 0.9254\n",
      "Epoch 34/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.1280 - acc: 0.9845 - val_loss: 0.2766 - val_acc: 0.9254\n",
      "Epoch 35/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.1288 - acc: 0.9856 - val_loss: 0.2766 - val_acc: 0.9254\n",
      "\n",
      "Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 36/50\n",
      "1809/1809 [==============================] - 0s 179us/step - loss: 0.1275 - acc: 0.9867 - val_loss: 0.2768 - val_acc: 0.9254\n",
      "Epoch 37/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.1278 - acc: 0.9856 - val_loss: 0.2766 - val_acc: 0.9254\n",
      "Epoch 38/50\n",
      "1809/1809 [==============================] - 0s 183us/step - loss: 0.1276 - acc: 0.9856 - val_loss: 0.2764 - val_acc: 0.9254\n",
      "Epoch 39/50\n",
      "1809/1809 [==============================] - 0s 187us/step - loss: 0.1260 - acc: 0.9867 - val_loss: 0.2764 - val_acc: 0.9254\n",
      "Epoch 40/50\n",
      "1809/1809 [==============================] - 0s 185us/step - loss: 0.1262 - acc: 0.9867 - val_loss: 0.2763 - val_acc: 0.9254\n",
      "Epoch 41/50\n",
      "1809/1809 [==============================] - 0s 182us/step - loss: 0.1268 - acc: 0.9862 - val_loss: 0.2760 - val_acc: 0.9254\n",
      "Epoch 42/50\n",
      "1809/1809 [==============================] - 0s 188us/step - loss: 0.1254 - acc: 0.9856 - val_loss: 0.2756 - val_acc: 0.9254\n",
      "Epoch 43/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.1257 - acc: 0.9856 - val_loss: 0.2753 - val_acc: 0.9254\n",
      "Epoch 44/50\n",
      "1809/1809 [==============================] - 0s 183us/step - loss: 0.1241 - acc: 0.9862 - val_loss: 0.2750 - val_acc: 0.9254\n",
      "Epoch 45/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.1241 - acc: 0.9867 - val_loss: 0.2749 - val_acc: 0.9254\n",
      "Epoch 46/50\n",
      "1809/1809 [==============================] - 0s 179us/step - loss: 0.1247 - acc: 0.9851 - val_loss: 0.2747 - val_acc: 0.9254\n",
      "Epoch 47/50\n",
      "1809/1809 [==============================] - 0s 183us/step - loss: 0.1227 - acc: 0.9862 - val_loss: 0.2747 - val_acc: 0.9254\n",
      "Epoch 48/50\n",
      "1809/1809 [==============================] - 0s 175us/step - loss: 0.1237 - acc: 0.9873 - val_loss: 0.2746 - val_acc: 0.9254\n",
      "Epoch 49/50\n",
      "1809/1809 [==============================] - 0s 187us/step - loss: 0.1237 - acc: 0.9878 - val_loss: 0.2745 - val_acc: 0.9254\n",
      "Epoch 50/50\n",
      "1809/1809 [==============================] - 0s 184us/step - loss: 0.1226 - acc: 0.9862 - val_loss: 0.2745 - val_acc: 0.9254\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_9 (InputLayer)            (None, 400)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_9 (Embedding)         (None, 400, 50)      1000000     input_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_7 (Bidirectional) (None, 400, 128)     58880       embedding_9[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling1d_3 (Glo (None, 128)          0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "global_max_pooling1d_3 (GlobalM (None, 128)          0           bidirectional_7[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_7 (Concatenate)     (None, 256)          0           global_average_pooling1d_3[0][0] \n",
      "                                                                 global_max_pooling1d_3[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 64)           16448       concatenate_7[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_7 (Dropout)             (None, 64)           0           dense_13[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 1)            65          dropout_7[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 1,075,393\n",
      "Trainable params: 1,075,393\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1809 samples, validate on 201 samples\n",
      "Epoch 1/50\n",
      "1809/1809 [==============================] - 7s 4ms/step - loss: 0.6929 - acc: 0.5119 - val_loss: 0.6925 - val_acc: 0.4826\n",
      "Epoch 2/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.6910 - acc: 0.5097 - val_loss: 0.6917 - val_acc: 0.4826\n",
      "Epoch 3/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.6882 - acc: 0.5064 - val_loss: 0.6884 - val_acc: 0.4826\n",
      "Epoch 4/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.6827 - acc: 0.6285 - val_loss: 0.6817 - val_acc: 0.8159\n",
      "Epoch 5/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.6729 - acc: 0.8911 - val_loss: 0.6690 - val_acc: 0.7861\n",
      "Epoch 6/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.6502 - acc: 0.8811 - val_loss: 0.6329 - val_acc: 0.8458\n",
      "Epoch 7/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.5835 - acc: 0.8977 - val_loss: 0.4963 - val_acc: 0.8706\n",
      "Epoch 8/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.5015 - acc: 0.8104 - val_loss: 0.4541 - val_acc: 0.7960\n",
      "Epoch 9/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.4574 - acc: 0.7888 - val_loss: 0.6879 - val_acc: 0.6567\n",
      "\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "Epoch 10/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.5642 - acc: 0.7048 - val_loss: 0.6327 - val_acc: 0.6468\n",
      "\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "Epoch 11/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.5147 - acc: 0.7048 - val_loss: 0.5976 - val_acc: 0.6468\n",
      "\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "Epoch 12/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.4880 - acc: 0.7125 - val_loss: 0.5661 - val_acc: 0.6567\n",
      "\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.0001.\n",
      "Epoch 13/50\n",
      "1809/1809 [==============================] - 4s 2ms/step - loss: 0.4687 - acc: 0.7219 - val_loss: 0.5463 - val_acc: 0.6667\n",
      "Epoch 00013: early stopping\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_10 (InputLayer)        (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "embedding_10 (Embedding)     (None, 400, 50)           1000000   \n",
      "_________________________________________________________________\n",
      "bidirectional_8 (Bidirection (None, 400, 256)          183296    \n",
      "_________________________________________________________________\n",
      "bidirectional_9 (Bidirection (None, 400, 128)          164352    \n",
      "_________________________________________________________________\n",
      "attention_with_context_3 (At (None, 128)               16640     \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 1,372,609\n",
      "Trainable params: 1,372,609\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 1809 samples, validate on 201 samples\n",
      "Epoch 1/50\n",
      "1024/1809 [===============>..............] - ETA: 6s - loss: 0.6929 - acc: 0.5283 "
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "  with tf.device('/device:GPU:0'):\n",
    "      data = pd.read_csv('./content/pubmed_cr_hep_ctl_abstracts_clean.csv')\n",
    "\n",
    "      for samples_per_class in range(500, 2500, 500):\n",
    "          for i in range(0, 1):\n",
    "              train_X, val_X, test_X, train_y, val_y, test_y, word_index = u.load_and_prec(\n",
    "                  samples_per_class, max_features, maxlen = maxlen, data = data)\n",
    "            \n",
    "              log_dir = get_log_dir(i, samples_per_class)\n",
    "              os.makedirs(log_dir, exist_ok = True)\n",
    "            \n",
    "              log_truths(log_dir, train_y, val_y, test_y)\n",
    "              \n",
    "              print(test_X.shape[1])\n",
    "              sequence_len = test_X.shape[1]\n",
    "                \n",
    "              def run_and_log_model_curry(model, model_name):\n",
    "                run_and_log_model(model, model_name, \n",
    "                                  train_X, train_y, val_X, val_y, test_X, \n",
    "                                  i, samples_per_class)\n",
    "\n",
    "              # CNN\n",
    "              cnn_model_built = models.cnn_model(sequence_len, [3, 4, 5], maxlen, max_features, embed_size, \n",
    "                                                 num_filters=200, drop_rate=0.2)\n",
    "              cnn_model_built.summary()\n",
    "              run_and_log_model_curry(cnn_model_built, 'cnn')\n",
    "\n",
    "              # LSTM\n",
    "              lstm_model = models.model_lstm_du(maxlen, max_features, embed_size)\n",
    "              lstm_model.summary()\n",
    "              run_and_log_model_curry(lstm_model, 'lstm')\n",
    "\n",
    "              # HAN\n",
    "              han_model = models.model_lstm_atten(maxlen, max_features, embed_size)\n",
    "              han_model.summary()\n",
    "              run_and_log_model_curry(han_model, 'han')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Copy of attention-musc.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
